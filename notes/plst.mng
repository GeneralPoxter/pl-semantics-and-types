\newif\ifcomments     %% include author discussion
\commentsfalse        %% toggle comments here

\documentclass{article}

\usepackage{fullpage}

\usepackage{bigfoot}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[dvipsnames]{xcolor}
\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\usepackage[hyphens]{url}
\usepackage[hidelinks,bookmarksnumbered,pdfencoding=auto,psdextra]{hyperref}
% From https://tex.stackexchange.com/a/430877/133551 and Heiko's comment
\pdfstringdefDisableCommands{%
  \def\({}%
  \def\){}%
}
\usepackage{supertabular}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{xspace}
\usepackage{ottalt}
\usepackage[T1]{fontenc}

\newcommand\scw[1]{\ifcomments\emph{\textcolor{violet}{#1}}\fi}

% requires dvipsnames
%\usepackage{lstpi}
%\usepackage{lsthaskell}
\newcommand\cd[1]{\lstinline[language=Haskell]{#1}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]

% force footnotes to be on a single page
\interfootnotelinepenalty=10000

\title{Programming Languages: Semantics and Types}
\author{Stephanie Weirich}

\begin{document}

\maketitle

\inputott{all-rules}

\section{Introduction}

\section{STLC}

Here, we give a precise definition of the syntax of the simply-typed lambda
calculus, its type system and operational semantics. If you are new to
programming language theory, we use this opportunity to introduce some of the
mathematical concepts that we will be using throughout the semester, such as
inductively defined grammars, recursive definitions, and proofs by structural
induction.

\subsection{Syntax}
The syntax of the simply-typed lambda calculus is defined by a set of terms
and their associated set of types. By convention, we will use $[[e]]$ to refer
to some arbitrary term and $[[e]]$ to refer to some arbitrary type.

\begin{definition}[Types]
The set of types is inductively defined by the following rules:
\begin{enumerate}
\item A base type, $[[Nat]]$, is a type.
\item If $[[tau1]]$ and $[[tau2]]$ are types, then $[[tau1 -> tau2]]$ is a type.
\end{enumerate}
The type $[[tau1 -> tau2]]$ represents the type of functions that take an argument of type $[[tau1]]$ and return a value of type $[[tau2]]$.
\end{definition}

\begin{definition}[Terms]
The set of terms is inductively defined by the following rules:
\begin{enumerate}
\item A natural number $k$ is a term.
\item A variable $x$ is a term. 
\item If $[[e]]$ is a term and $x$ is a variable, then $[[\x.e]]$ is a term (called a lambda abstraction).
The variable $x$ is the parameter and $e$ is the body is the body of the abstraction.
\item If $[[e1]]$ and $[[e2]]$ are terms, then $[[e1 e2]]$ is a term (called a function application).
\end{enumerate}
\end{definition}

The definition of terms refers to two other sets: natural numbers and
variables. The set of natural numbers, $\mathbb{N}$, are an infinite set of
numbers 0, 1, \ldots. We will treat variables more abstractly. We assume that
there is some infinite set of variable names, called $\mathcal{V}$, and that
given any finite set of variables, we can always find some variable that is
not in contained in that set. (We call this variable \emph{fresh} because we
haven't used it yet.)

Now, the above is a wordy way of describing an inductively-defined grammar of
abstract syntax trees.  In the future, we will use a more concise notation,
called Bakus-Naur form. For example, in BNF form, we can provide a concise
definition of the grammars for types and terms as follows. 

\[
\begin{array}{llcl}
\textit{numbers} & [[k]] & \in & \mathbb{N} \\
\textit{variables} & [[x]] & \in & \mathcal{V} \\
\textit{types} & [[tau]] &::=& [[Nat]]\ |\ [[tau1 -> tau2]] \\
\textit{terms} & [[e]]   &::=& [[k]]\ |\ [[x]]\ |\ [[\x.e]]\ |\ [[e1 e2]] \\
\end{array}
\]

Because types and terms are inductively design sets, we can reason about them
using recursion and induction principles.  The recursion princple means that
we define recursive functions that takes terms or types as arguments and know
that the functions are total, as long as we call the functions over smaller
subterms.

For example, one function that we might define calculates the set of
\emph{free} variables in a term.

\begin{definition}[Free variables] 
We define the operation $[[fv(e)]]$, which calculates the set of variables that 
occur \emph{free} in some term $[[e]]$, by structural recursion on the term. In the last line 
of this function, we remove the argument $x$
\[
\begin{array}{lcll}
[[ fv(k)       ]] &=& [[ emptyset ]]  & \textit{ emptyset }  \\
[[ fv(x)       ]] &=& [[ { x } ]]  & \textit{ singleton set } \\
[[ fv(e1 e2)   ]] &=& [[ (fv e1) U (fv e2) ]] & \textit{ union of sets } \\
[[ fv(\x . e)  ]] &=& [[ (fv e) - { x } ]] & \textit{ remove variable } \\
\end{array}
\]
\end{definition}

Variables that appear in terms that are not free are called \emph{bound}. For
example, in the term $[[\x. x y]]$, we have $x$ bound and $y$ free. Some
variables may occur in both bound and free positions in terms; for example,
$x$ in the term $[[(\x. x y) x]]$.

Here is another example of a recursively defined function. Sometimes we would
like to change the names of free variables in terms.

A \emph{renaming}, $[[xi]]$, is a mapping from variables to variables. A
renaming has a \emph{domain}, $[[dom xi]]$ and a \emph{range} $[[rng xi]]$.
We use the notation $[[y/x, xi]]$ to create the renaming that maps $[[x]]$ to
$[[y]]$, but otherwise works like $[[xi]]$.

\begin{definition}[Renaming application] We define the application of a
  renaming function to a term, commonly written with postfix notation
  $[[e<xi>]]$, as follows:
\[
\begin{array}{lcl}
[[ k< xi >      ]] &=& [[ k ]] \\
[[ x< xi >      ]] &=& [[ xi x ]] \\
[[ (e1 e2) < xi >  ]] &=& [[ (e1 <xi>) (e2 <xi>) ]] \\
[[ (\x . e) < xi > ]] &=& [[ \x . (e < x/x, xi >) ]] \\
\end{array}
\]
\end{definition}
We can only apply a renaming to a term when its domain is at least as big as
all of the free variables defined in the term. In that case, our renaming
function is total: it produces an answer for any such term.

We have to be a bit careful in the last line of this definition. What if
$[[xi]]$ already maps the variable $[[x]]$ to some other variable? Our goal is
to only rename free variables: the function should leave the bound variables
alone and inside the body of $[[\x.e]]$, the variable $[[x]]$ is occurs bound,
not free. By updating the renaming to $[[x/x,xi]]$ in the recursive call, we
force the renaming that we use for the body of the abstraction to not change
$[[x]]$.

There is one final definition of a function defined by structural recursion
over terms: the application of a \emph{substitution} that applies to all free
variables in the term. 

A \emph{substitution}, $[[sigma]}$ is a mapping from variables to terms. As
above, it has a \emph{domain} (a set of variables) and a \emph{range} (this
time a set of terms). We use the notation $[[e/x,sigma]]$ to refer to the substitution that maps variable $[[x]]$ to term $[[e]]$, but otherwise acts like
$[[sigma]]$.

As before, this definition only applies when the free variables of the term
are contained within the domain of the substitution. Furthermore, when
substituting in the body of an abstraction, we must extend the substitution
with a definition for the bound variable (mapping it to itself).

\begin{definition}[Substitution application] We define the application of a
  substitution function to a term, written with postfix notation
  $[[ e[sigma] ]]$, as follows:
\[
\begin{array}{lcl}
[[ k [sigma]        ]] &=& [[ k ]] \\
[[ x [sigma]        ]] &=& [[ sigma x ]] \\
[[ (e1 e2) [sigma]  ]] &=& [[ (e1 [sigma] ) (e2 [sigma] ) ]] \\
[[ (\x . e) [sigma] ]] &=& [[ \x . (e [ x/x, sigma ]) ]] \\
\end{array}
\]
\end{definition}


\paragraph{Variable binding, alpha-equivalence and all that} At this point, we
will start to be somewhat informal when it comes to bound variables in
terms. We don't really want to distinguish between terms that differ only in
their use of bound variables, such as $[[\x.x]]$ and $[[\y.y]]$. The relation
$\alpha$-equivalence relates such terms, and from this point forward we will
``work up-to-$\alpha$-equivalence. What this means practically is that on one
hand, we must be sure that our definitions don't really depend on the names of
bound variables. In return, we can always assume that any bound variable is
distinct from any other variable, if we need it to be.

Here we have a conundrum. It is common practice to describe lambda calculus
terms as we have done above (sometimes called using a named or nominal
representation of variables). But getting the details right is difficult (it
requires maintaining careful invariants about all definitions) and subtle. If
you are working with a proof assistant, you really do need to get the details
right, but it also makes sense to use an approach (such as de Bruijn indices)
where the details are easier to get right. This is what we will do in the
accompanying mechanized proofs.

However, because using a named representation is standard practice we will
continue to use that approach in these notes, glossing over some details. This
will allow us to stay roughly equivalent to the proof scripts (which have
other details). Because of the informal nature of our discussion, threre will
probably be minor errors related to variable naming; but we won't stress about
them.

\section{Type system}
Next we will define a typing relation for STLC. This relation has the form
$[[G |- e : tau]]$, which is read as ``in the typing context $[[G]]$, the term
$[[e]]$ has type $[[tau]]$.''  The typing context $[[G]]$, tells us what the
types of free variables should be. Therefore, we can view it as a finite map
from variables to types, and write it by listing all of the associations
$[[x:tau]]$.  If a term is in this relation we say that it ``type checks''.

We define the typing relation inductively, using the following rules. A term
type checks if we can find some tree that puts these rules together in a
\emph{derivation}. In each rule, the part below the line is the conclusion of
the rule, and the rule may have multiple premises. In a derivation tree, each
premise must be satisfied by subderivations, bottoming out with rules such as
\rref{t-var} or \rref{t-const} that do not have any premises for the same
relation.

\begin{figure}[h]
\drules[t]{$[[G |- e : tau ]]$}{in context $[[G]]$, term $e$ has type $[[tau]]$}
{const,var,abs,app}
\caption{STLC}
\label{fig:stlc-typing}
\end{figure}

In the variable rule, we look up the type of the variable in the typing
context. This variable must have a definition in $[[G]]$ for this rule to be
used. If there is no type associated with $[[x]]$, then we say that the
variable is unbound and that the term fails to \emph{scope-check}.

In \rref{t-abs}, the rule for abstractions, we type check the body of the
function with a context that has been extended with a type for the bound
variable. The type of an abstraction is a function type $[[tau1->tau2]]$, that
states the required type of the parameter $[[tau1]]$ and the result type of
the body $[[tau2]]$.

\Rref{t-app}, which checks the application of functions, requires that the
argument to the function has the same type required by the function.

\subsection{Operational Semantics}

Is this type system meaningful? Our type system makes a distinction between
terms that type check (such as $[[(\x.x)3]]$) and terms that do not, such as 
$[[(2 5)]]$. But how do we know that this distinction is useful? Do we have the right
rules?

The key property that we want is called \emph{type safety}. If a term type
checks, we should be able to evaluate it without triggering a certain class of
errors. 


Small-step operational semantics describe how a term evaluates in a sequence
of single reduction steps. We use the notation $[[e ~> e']]$ to mean that the term $[[e]]$
reduces to the term $[[e']]$ in one step. 

The rules are as follows:

\drules[s]{$[[e ~> e']]$}{term $e$ steps to $[[e']]$}
{beta,app-congOne,app-congTwo}

In \rref{step-beta} note that the argument must be a value $[[v]]$ before we 
substitute it for the parameter in a function application. This rule is the key of 
a \emph{call-by-value} semantics. 

We can define values as subgrammar of terms: 

\[  [[v]] ::= [[k]] |\ [[\x.e]] \]

\subsection{Type Safety}

Type safety is a crucial property of a typed programming language. It ensures
that a well-typed program will never ``go wrong'' during execution. For the
simply-typed lambda calculus, this means a program will not get stuck in a
state where it cannot take a reduction step but is not a final value.

The type safety proof is usually defined through two lemmas: Progress and
Preservation.

The \emph{preservation} lemma property states that if a term $[[e]]$ has type
$[[tau]]$, and it takes a single reduction step to $[[e']]$, then the new term
must also have the exact same type $[[tau]]$. In other words, the type is
``preserved'' through evaluation.

\begin{lemma}[Preservation]
If $[[ |- e : tau ]]$ and $[[e ~> e']]$ then $[[ |- e' : tau]]$.
\end{lemma}
Proof Sketch: The proof is by induction on the derivation of the reduction
or on the typing derivation. Either way works.

You examine each reduction rule from the small-step semantics and show that it preserves the type. The most complex case is beta reduction, which relies on a key lemma: substitution. This lemma says that if we have a well-typed argument 
for a function, we can use substitution to replace the parameter with this value and 
have a term that is still well typed. 

\begin{corollary}[Single Substitution]
  If $[[ x:tau1 |- e : tau2 ]]$ and $[[ |- v : tau2 ]]$ then $[[ |- e [v/x] : tau1 ]]$
\end{corrollary}

However, to prove this lemma, we must first generalize it. We cannot prove the
lemma directly as stated, we need a version that gives us a stronger induction
hypothesis.  Here is a generalization of the lemma, that works for any
substitution (not just a singleton one) and any context of terms (not just one
with a single variable assumption). Every term in the range of the substitution must have the type described by the context.

\begin{lemma}[Substitution]
  If $[[ G |- e : tau ]]$ and for all $[[x]] \in [[dom sigma]]$, we have
  $[[D |- sigma x : G x ]]$, then $[[D |- e[sigma] : tau ]]$.
\end{lemma}
Proof Sketch: The proof is by induction on the typing derivation.

\medskip

The section lemma, called \emph{progress} states that any well-typed term that
has not been completely reduced can always take at least one more reduction
step. It ensures that a well-typed term is not ``stuck.'' (i.e. is not a value
but cannot step).


\begin{lemma}[Progress]
If $[[ |- e : tau ]]$ then either $e$ is a value or there exists an $[[e']]$ such that 
$[[ e ~> e' ]]$.
\end{lemma}

Intuition: This property 

\section{Extending with Natural Numbers}
We now extend the system with a base type for natural numbers, $[[Nat]]$, and
associated constants and operations.

\subsection{New Syntax}
We add the following to our set of types and terms:
\begin{itemize}
\item \textbf{New base type:} $[[Nat]]$ is a type.
\item \textbf{New terms:}
\begin{itemize}
\item The constant $[[zero]]$ is a term. Informally, we may write this term as $0$.
\item If $[[e]]$ is a term, $[[succ e]]$ is a term (successor).
\item If $[[e]]$, $[[e1]]$ and $[[e2]]$ are terms, then $[[natrec e of { zero => e1 ; succ x => e2 }]]$ is a term.
\end{itemize}
\end{itemize}

\subsection{New Typing Rules}
We introduce new typing rules for the natural number constants and the successor function.

\drules[t]{$[[G |- e :tau ]]$}{in context $[[G]]$, term $e$ has type $[[tau]]$}
{zero,succ,nrec}

\end{document}
